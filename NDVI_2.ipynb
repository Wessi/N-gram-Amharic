{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wessi/N-gram-Amharic/blob/main/NDVI_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0MIvC3zFhMaz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKSi3dFGlLoU",
        "outputId": "6cb2089e-958a-4ae1-a0e1-8b9df55ffb5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6FcdJqqPiLLR"
      },
      "outputs": [],
      "source": [
        "merged_data = pd.read_excel('/content/drive/MyDrive/merged_ndvi_2017_2023.xlsx')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data.head(5).to_csv('top_5_rows.csv', index=False)"
      ],
      "metadata": {
        "id": "-cDyAl-nt9K3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Generate new column names as NDVI_1, NDVI_2, ..., NDVI_133\n",
        "new_columns = [f'NDVI_{i+1}' for i in range(133)]\n",
        "\n",
        "# Step 2: Rename the NDVI columns in the merged_data DataFrame\n",
        "merged_data.columns = ['GRID_CODE'] + new_columns\n",
        "\n",
        "# Step 3: Verify that the column names have been updated\n",
        "print(merged_data.columns)\n"
      ],
      "metadata": {
        "id": "TX9hIf1vB-Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data.head()"
      ],
      "metadata": {
        "id": "KP8Ov_quDDWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69MelbwfXtJ8"
      },
      "outputs": [],
      "source": [
        "merged_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLC7rPuiEkqX"
      },
      "outputs": [],
      "source": [
        "df_dropped = merged_data.drop(columns=merged_data.filter(like='_2023').columns)\n",
        "df_dropped.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data.head(1)"
      ],
      "metadata": {
        "id": "ah6I-qlo6qXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i71wyy2dm7_k"
      },
      "outputs": [],
      "source": [
        "merged_data.drop('bbox', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlMS98QhmTnY"
      },
      "outputs": [],
      "source": [
        "merged_data.drop('2021CPSZs', axis=1, inplace=True)\n",
        "\n",
        "merged_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKrGDDF4khSL"
      },
      "outputs": [],
      "source": [
        "merged_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vaXbicSnOhd"
      },
      "outputs": [],
      "source": [
        "merged_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmlv1cE-nTxE"
      },
      "outputs": [],
      "source": [
        "null_values = merged_data.isnull().sum()\n",
        "null_columns = null_values[null_values > 0]\n",
        "print(\"\\nColumns with missing values:\\n\", null_columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F6ytFfyqvnu"
      },
      "source": [
        "**Average NDVI Values for each Grids**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuE1TR-Hngcl"
      },
      "outputs": [],
      "source": [
        "ndvi_columns = ['NDVI_' + str(i) for i in range(17, 36)]\n",
        "merged_data['Average_NDVI'] = merged_data[ndvi_columns].mean(axis=1)\n",
        "average_ndvi_per_grid = merged_data.groupby('GRID_CODE')['Average_NDVI'].mean().reset_index()\n",
        "\n",
        "average_ndvi_per_grid.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urXC1BQWrQA7"
      },
      "source": [
        "**NDVI Variability for ach Grid**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNfks1QRvkdi"
      },
      "outputs": [],
      "source": [
        "\n",
        "merged_data['Variability'] = merged_data[ndvi_columns].std(axis=1)\n",
        "std_for_each_grid = merged_data[['GRID_CODE', 'Variability']]\n",
        "std_for_each_grid.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AygXicXazKaV"
      },
      "source": [
        "**Peak NDVI for each Grid**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzSHZgylwKU3"
      },
      "outputs": [],
      "source": [
        "merged_data['Peak'] = merged_data[ndvi_columns].max(axis=1)\n",
        "peak_for_each_grid = merged_data[['GRID_CODE', 'Peak']]\n",
        "peak_for_each_grid.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc2rJ9Jp5cWE"
      },
      "source": [
        "**1. Precision Factor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bE-RFsfw9NTh"
      },
      "outputs": [],
      "source": [
        "merged_data['precision_factor'] = peak_for_each_grid['Peak'] / average_ndvi_per_grid['Average_NDVI']\n",
        "\n",
        "precision_factor_for_each_grid = merged_data[['GRID_CODE', 'precision_factor']]\n",
        "precision_factor_for_each_grid.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3F26XSRIHDC"
      },
      "outputs": [],
      "source": [
        "precision_factor_for_each_grid.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMlwe4QN5vfL"
      },
      "source": [
        "**2. Inclusion Factor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z9fHw7uA600"
      },
      "outputs": [],
      "source": [
        "regional_benchmark = average_ndvi_per_grid['Average_NDVI'].mean()\n",
        "print(regional_benchmark)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkSyEUDw_eSC"
      },
      "outputs": [],
      "source": [
        "merged_data['inclusion_factor'] = regional_benchmark/ std_for_each_grid['Variability']\n",
        "\n",
        "inclusion_factor_for_each_grid = merged_data[['GRID_CODE', 'inclusion_factor']]\n",
        "inclusion_factor_for_each_grid.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99u1TAAvJVbd"
      },
      "outputs": [],
      "source": [
        "inclusion_factor_for_each_grid.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqjJgUZd50u2"
      },
      "source": [
        "**3. Consistency Factor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIsvSxLdCana"
      },
      "outputs": [],
      "source": [
        "merged_data['coefficient_of_variablity'] = std_for_each_grid['Variability']/ average_ndvi_per_grid['Average_NDVI']\n",
        "\n",
        "coefficient_of_variablity_for_each_grid = merged_data[['GRID_CODE', 'coefficient_of_variablity']]\n",
        "coefficient_of_variablity_for_each_grid.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1QCNHFdDFRK"
      },
      "outputs": [],
      "source": [
        "merged_data['consistency_factor'] = 1/merged_data['coefficient_of_variablity']\n",
        "consistency_factor_for_each_grid = merged_data[['GRID_CODE', 'consistency_factor']]\n",
        "consistency_factor_for_each_grid.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QimQUApuJfPe"
      },
      "outputs": [],
      "source": [
        "consistency_factor_for_each_grid.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3KNLX1X5-KM"
      },
      "source": [
        "**4. Optimization Factor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2oxmCqcEW6k"
      },
      "outputs": [],
      "source": [
        "merged_data = merged_data.drop(columns=['GRID-CODE'], errors='ignore')\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "ndvi_train_scaled = scaler.fit_transform(merged_data[ndvi_columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJC-pXNPEgnO"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_sequences(data, n_steps):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - n_steps):\n",
        "        X.append(data[i:i + n_steps])\n",
        "        y.append(data[i + n_steps])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "n_steps = 6\n",
        "\n",
        "X_train, y_train = create_sequences(ndvi_train_scaled, n_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzjUC3SyExcP"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu', input_shape=(n_steps, len(ndvi_columns)), return_sequences=True))\n",
        "model.add(LSTM(32, activation='relu', return_sequences=False))\n",
        "model.add(Dense(len(ndvi_columns)))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "id": "jE5IXr5Drimu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming `merged_data` contains columns: 'GRID_CODE', 'NDVI_1', 'NDVI_2', ..., 'NDVI_152'\n",
        "# Load your merged_data DataFrame\n",
        "# merged_data = pd.read_csv('path_to_your_data.csv')\n",
        "\n",
        "# Extract NDVI columns\n",
        "ndvi_columns = [f'NDVI_{i}' for i in range(1, 32)]  # Assuming 152 columns (8 years * 19 values per year)\n",
        "grid_codes = merged_data['GRID_CODE'].values\n",
        "ndvi_data = merged_data[ndvi_columns].values  # Shape: (num_grids, 152)\n",
        "\n",
        "def create_sequences(data, input_steps=133, output_steps=19):\n",
        "    \"\"\"\n",
        "    Prepare sequences where inputs are the past 133 values (7 years)\n",
        "    and outputs are the next 19 values (1 year).\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    for row in data:\n",
        "        # Use the first 133 NDVI values as input\n",
        "        X.append(row[:input_steps])\n",
        "        # Use the next 19 NDVI values as output\n",
        "        y.append(row[input_steps:input_steps + output_steps])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Create input (X) and output (y) sequences\n",
        "input_steps = 133  # 19 values * 7 years\n",
        "output_steps = 19  # Predict 19 values for the next year\n",
        "X, y = create_sequences(ndvi_data, input_steps, output_steps)\n",
        "\n",
        "print(f\"Input shape: {X.shape}, Output shape: {y.shape}\")\n"
      ],
      "metadata": {
        "id": "Hy_3128wB0bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from tensorflow.keras.models import model_from_json\n",
        "\n",
        "# Save the model architecture and weights separately using pickle\n",
        "def save_model_pickle(model, filename='ndvi_model.pkl'):\n",
        "    # Step 1: Save the model architecture as JSON\n",
        "    model_json = model.to_json()\n",
        "\n",
        "    # Step 2: Save the model weights\n",
        "    model_weights = model.get_weights()\n",
        "\n",
        "    # Step 3: Use pickle to save both JSON and weights\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump((model_json, model_weights), f)\n",
        "    print(f\"Model saved as {filename}\")\n",
        "\n",
        "# Assuming `model` is your trained model\n",
        "save_model_pickle(model)\n"
      ],
      "metadata": {
        "id": "twfEhnXC3TLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model_pickle('ndvi_model.pkl')\n",
        "y_pred = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "3ITbsQJa_wRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred.shape"
      ],
      "metadata": {
        "id": "wap9F2NFAKNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from tensorflow.keras.models import model_from_json\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the saved model using pickle\n",
        "def load_model_pickle(filename='ndvi_model.pkl'):\n",
        "    with open(filename, 'rb') as f:\n",
        "        model_json, model_weights = pickle.load(f)\n",
        "    loaded_model = model_from_json(model_json)\n",
        "    loaded_model.set_weights(model_weights)\n",
        "    return loaded_model\n",
        "\n",
        "# Load the model\n",
        "loaded_model = load_model_pickle('ndvi_model.pkl')\n",
        "\n",
        "# Compile the loaded model\n",
        "loaded_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "print(\"Model loaded and compiled successfully.\")\n"
      ],
      "metadata": {
        "id": "dEcn4wl34-b5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_input_no_scaler(grid_code, past_ndvi_data, n_steps):\n",
        "    \"\"\"\n",
        "    Prepare the input data using the provided GRID_CODE and past NDVI values without scaling.\n",
        "    \"\"\"\n",
        "    if len(past_ndvi_data) != n_steps:\n",
        "        raise ValueError(f\"Expected {n_steps} NDVI values, but got {len(past_ndvi_data)}\")\n",
        "\n",
        "    # Create an array with repeated GRID_CODE and NDVI data for each timestep\n",
        "    input_data = np.array([[grid_code] + past_ndvi_data])\n",
        "\n",
        "    # Repeat the grid_code for each timestep and reshape to match the model's input shape\n",
        "    X_input = np.tile(input_data, (n_steps, 1)).reshape(1, n_steps, -1)\n",
        "    return X_input\n"
      ],
      "metadata": {
        "id": "7_H1mqrB5ymv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "\n",
        "# Save the trained model\n",
        "model.save('ndvi_model.h5')\n",
        "\n",
        "# Save the scaler using pickle\n",
        "with open('scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "print(\"Model and scaler saved successfully.\")"
      ],
      "metadata": {
        "id": "pnHcTbW4xoyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVREdq7Oyeos"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "training_loss = history.history['loss']\n",
        "validation_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(training_loss, label='Training Loss', color='blue')\n",
        "plt.plot(validation_loss, label='Validation Loss', color='orange')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqw0Tj7Em8F9"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_lQXGvcE_4s"
      },
      "outputs": [],
      "source": [
        "ndvi_2024 = pd.read_excel('/content/drive/MyDrive/NDVI_2024.xlsx')\n",
        "ndvi_2024.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ky9_8ZGxvb5"
      },
      "outputs": [],
      "source": [
        "ndvi_2023 = pd.read_excel('/content/drive/MyDrive/NDVI_2023.xlsx')\n",
        "ndvi_2023.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RwiKfIInYvd"
      },
      "outputs": [],
      "source": [
        "ndvi_2024 = ndvi_2024.drop(columns=['bbox',\t'GRID_CODE',\t'2021CPSZs',\t'NDVI_0',\t'NDVI_1',\t'NDVI_2',\t'NDVI_3'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1z4v4vtmyzM4"
      },
      "outputs": [],
      "source": [
        "ndvi_2023 = ndvi_2023.drop(columns=['bbox',\t'GRID_CODE',\t'2021CPSZs',\t'NDVI_0',\t'NDVI_1',\t'NDVI_2',\t'NDVI_3', 'NDVI_4','NDVI_5','NDVI_6','NDVI_7','NDVI_8','NDVI_9','NDVI_10','NDVI_11','NDVI_12','NDVI_13','NDVI_14','NDVI_15','NDVI_16'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGhfV96coANh"
      },
      "outputs": [],
      "source": [
        "ndvi_2023.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypBhgkkb7zoJ"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "ndvi_2023_scaled = scaler.fit_transform(ndvi_2023)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVuB2qDIQVyI"
      },
      "outputs": [],
      "source": [
        "n_steps = 6\n",
        "def create_sequences(data, n_steps):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - n_steps):\n",
        "        X.append(data[i:i + n_steps])\n",
        "        y.append(data[i + n_steps])\n",
        "    return np.array(X), np.array(y)\n",
        "X_test, y_test = create_sequences(ndvi_2023_scaled, n_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmgY3XH2Qo2J"
      },
      "outputs": [],
      "source": [
        "y_test_pred_scaled = model.predict(X_test)\n",
        "\n",
        "y_test_pred = scaler.inverse_transform(y_test_pred_scaled)\n",
        "y_test_actual = scaler.inverse_transform(y_test)\n",
        "y_test_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YP4GI9ypCFJH"
      },
      "outputs": [],
      "source": [
        "print(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54VzQTesQ_R6"
      },
      "outputs": [],
      "source": [
        "rmse = np.sqrt(mean_squared_error(y_test_actual, y_test_pred))\n",
        "mae = mean_absolute_error(y_test_actual, y_test_pred)\n",
        "performance_metrics = {\n",
        "    'RMSE': rmse,\n",
        "    'MAE': mae\n",
        "}\n",
        "\n",
        "print(\"Performance Metrics on 2023:\")\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"MAE: {mae}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYQW01WyUdl4"
      },
      "outputs": [],
      "source": [
        "r2 = r2_score(y_test_actual, y_test_pred)\n",
        "r2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4Hyr3tZSHjq"
      },
      "outputs": [],
      "source": [
        "optimization_factor = r2/(rmse+mae)\n",
        "print(optimization_factor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNLcMesKka1B"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create sequences for training\n",
        "def create_sequences(data, n_steps_in, n_steps_out):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - n_steps_in - n_steps_out + 1):\n",
        "        X.append(data[i:i + n_steps_in])\n",
        "        y.append(data[i + n_steps_in:i + n_steps_in + n_steps_out])\n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQvOZmsrf1J0"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "n_steps_in = 15  # Look-back period\n",
        "n_steps_out = 4  # Prediction window\n",
        "\n",
        "# Scale the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "ndvi_train_scaled = scaler.fit_transform(merged_data[ndvi_columns])\n",
        "\n",
        "# Prepare training data\n",
        "X_train, y_train = create_sequences(ndvi_train_scaled, n_steps_in, n_steps_out)\n",
        "X_train = X_train.reshape((X_train.shape[0], n_steps_in, len(ndvi_columns)))\n",
        "\n",
        "y_train = y_train[:,:,0] # Select the first feature from all time steps\n",
        "y_train = y_train.reshape((y_train.shape[0], n_steps_out))\n",
        "\n",
        "\n",
        "# Define and compile the model\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu', input_shape=(n_steps_in, len(ndvi_columns)), return_sequences=True))\n",
        "model.add(LSTM(32, activation='relu', return_sequences=False))\n",
        "model.add(Dense(n_steps_out))  # Output layer for 4 future NDVI values\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6WU8X665qT_"
      },
      "source": [
        "# **PICO SCORE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqOHdBS7U_nY"
      },
      "outputs": [],
      "source": [
        "def generate_base_score():\n",
        "    return np.random.randint(300, 801)\n",
        "base_score = generate_base_score()\n",
        "print(f\"Randomly generated base score: {base_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6wJGd7b9JZg"
      },
      "outputs": [],
      "source": [
        "merged_data['pico_score'] =(merged_data['precision_factor'] + merged_data['inclusion_factor'] +  merged_data['consistency_factor'] +\n",
        "                            optimization_factor)\n",
        "pico_score_for_each_grid = merged_data[['GRID_CODE', 'pico_score',\n",
        "                                        'precision_factor', 'inclusion_factor',\n",
        "                                        'consistency_factor']]\n",
        "pico_score_for_each_grid.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fEY6T-QlGMz"
      },
      "outputs": [],
      "source": [
        "# Find the minimum and maximum of the pico_score\n",
        "min_score = merged_data['pico_score'].min()\n",
        "max_score = merged_data['pico_score'].max()\n",
        "\n",
        "# Define the new range\n",
        "new_min = 300\n",
        "new_max = 800\n",
        "\n",
        "# Apply the mapping formula to map pico_score to the range of 300 to 800\n",
        "merged_data['fico_score'] = ((merged_data['pico_score'] - min_score) / (max_score-min_score)) * (new_max - new_min) + new_min\n",
        "\n",
        "# Display the updated DataFrame with the mapped pico_score\n",
        "fico_score_for_each_grid = merged_data[['GRID_CODE', 'pico_score', 'fico_score',\n",
        "                                        'precision_factor', 'inclusion_factor',\n",
        "                                        'consistency_factor']]\n",
        "\n",
        "# Display the head of the new DataFrame\n",
        "fico_score_for_each_grid.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPLcuxXIlQMB"
      },
      "outputs": [],
      "source": [
        "merged_data['pico_score'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Jnxvd5slcTY"
      },
      "outputs": [],
      "source": [
        "merged_data['fico_score'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWOYeVyZl9TZ"
      },
      "outputs": [],
      "source": [
        "# Check the minimum and maximum pico_score\n",
        "min_score = merged_data['pico_score'].min()\n",
        "max_score = merged_data['pico_score'].max()\n",
        "\n",
        "# Print out the minimum and maximum to ensure they are different\n",
        "print(f\"Min PICO Score: {min_score}\")\n",
        "print(f\"Max PICO Score: {max_score}\")\n",
        "\n",
        "# If the min and max are too close, adjust the range\n",
        "if min_score == max_score:\n",
        "    print(\"All PICO scores are the same. Mapping will result in the same value for all.\")\n",
        "else:\n",
        "    # Define the new range (300 to 800)\n",
        "    new_min = 300\n",
        "    new_max = 800\n",
        "\n",
        "    # Apply the mapping formula to map pico_score to the range of 300 to 800\n",
        "    merged_data['pico_score_mapped'] = ((merged_data['pico_score'] - min_score) / (max_score - min_score)) * (new_max - new_min) + new_min\n",
        "\n",
        "    # Display the updated DataFrame with the mapped pico_score\n",
        "    pico_score_for_each_grid = merged_data[['GRID_CODE', 'pico_score', 'pico_score_mapped',\n",
        "                                            'precision_factor', 'inclusion_factor',\n",
        "                                            'consistency_factor']]\n",
        "\n",
        "    # Display the head of the new DataFrame\n",
        "    print(pico_score_for_each_grid.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ev1hBYR9kHP4"
      },
      "outputs": [],
      "source": [
        "pico_score_for_each_grid['pico_score'].min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zomJN_jokVSL"
      },
      "outputs": [],
      "source": [
        "pico_score_for_each_grid['pico_score'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPUraiA9NZof"
      },
      "outputs": [],
      "source": [
        "# Define the classification based on pico_score_mapped ranges\n",
        "conditions = [\n",
        "    (merged_data['fico_score'] < 580),\n",
        "    (merged_data['fico_score'] >= 580) & (merged_data['fico_score'] <= 669),\n",
        "    (merged_data['fico_score'] >= 670) & (merged_data['fico_score'] <= 739),\n",
        "    (merged_data['fico_score'] >= 740) & (merged_data['fico_score'] <= 799),\n",
        "    (merged_data['fico_score'] >= 800)\n",
        "]\n",
        "\n",
        "# Corresponding labels for each range\n",
        "labels = ['Poor', 'Fair', 'Good', 'Very Good', 'Exceptional']\n",
        "\n",
        "# Apply the classification to create a new column pico_score_class\n",
        "merged_data['fico_class'] = pd.cut(merged_data['fico_score'],\n",
        "                                         bins=[-float(\"inf\"), 580, 669, 739, 799, float(\"inf\")],\n",
        "                                         labels=labels)\n",
        "\n",
        "# Display the updated DataFrame to verify the classification\n",
        "fico_score_class_for_each_grid = merged_data[['GRID_CODE', 'fico_score', 'fico_class']]\n",
        "fico_score_class_for_each_grid.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIUFSYT1NgFe"
      },
      "outputs": [],
      "source": [
        "fico_score_class_for_each_grid[fico_score_class_for_each_grid['fico_class'] == 'Poor'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISK3V8aFNjHF"
      },
      "outputs": [],
      "source": [
        "fico_score_class_for_each_grid[fico_score_class_for_each_grid['fico_class'] == 'Good'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sY3EcSWYNqVx"
      },
      "outputs": [],
      "source": [
        "fico_score_class_for_each_grid[fico_score_class_for_each_grid['fico_class'] == 'Fair'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VBXn9TTNwqZ"
      },
      "outputs": [],
      "source": [
        "fico_score_class_for_each_grid[fico_score_class_for_each_grid['fico_class'] == 'Very Good'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znTcXlQ8N6J5"
      },
      "outputs": [],
      "source": [
        "fico_score_class_for_each_grid[fico_score_class_for_each_grid['fico_class'] == 'Exceptional'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5gPgHyxOLZB"
      },
      "outputs": [],
      "source": [
        "location_data= pd.read_excel(\"/content/drive/MyDrive/Grid2023LateSeasonOromia.xlsx\")\n",
        "location_data = location_data[0:]\n",
        "location_data.columns = location_data.iloc[0]\n",
        "location_data = location_data[1:]\n",
        "location_data.head()\n",
        "selected_indices = [i for i in range(0, 7) if i not in [1,2, 6,]]\n",
        "selected_columns = location_data.columns[selected_indices]\n",
        "location_data = location_data[selected_columns]\n",
        "\n",
        "location_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNNIUaY-PxDo"
      },
      "outputs": [],
      "source": [
        "!pip install shapely\n",
        "from shapely.geometry import Polygon\n",
        "\n",
        "coordinates=location_data[['X_LL','Y_LL']]\n",
        "# coordinates=location_data[['X_LL','Y_LL']]\n",
        "pol=[]\n",
        "xx= coordinates['X_LL']\n",
        "yy= coordinates['Y_LL']\n",
        "for i, x in enumerate(xx):\n",
        "    pol.append([xx.iloc[i],yy.iloc[i]])\n",
        "polygon_all = Polygon(pol) # Now Polygon is defined and can be used\n",
        "xp,yp = polygon_all.exterior.xy\n",
        "plt.plot(xp,yp)\n",
        "# Set plot title and labels\n",
        "plt.title('Grids covered by our data collection process by location')\n",
        "plt.xlabel('Latitude')\n",
        "plt.ylabel('Longitude')\n",
        "fig =plt.plot(xp, yp, color='green')\n",
        "fig = plt.gcf()\n",
        "\n",
        "# Plot the data\n",
        "plt.plot(xp, yp, color='green')\n",
        "\n",
        "# Save the figure\n",
        "fig.savefig(\"map.png\")\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8SZZV1YQfml"
      },
      "outputs": [],
      "source": [
        "# Convert coordinates to GeoDataFrame\n",
        "location_data['geometry'] = location_data.apply(lambda row: Point(row['X_LL'], row['Y_LL']), axis=1)\n",
        "gdf = gpd.GeoDataFrame(location_data, geometry='geometry', crs=\"EPSG:4326\")\n",
        "\n",
        "gdf = gdf.merge(merged_data[['GRID_CODE', 'fico_score']], on='GRID_CODE', how='left') # Adjust 'on' if needed\n",
        "\n",
        "# Add a new column 'fico_score_class' to gdf and populate it using the 'fico_score' column\n",
        "gdf['fico_score_class'] = gdf['fico_score'].apply(assign_fico_class) # Apply the classification to the 'fico_score' column in gdf\n",
        "\n",
        "\n",
        "# Define colors for each FICO class\n",
        "fico_colors = {\n",
        "    'Poor': 'red',\n",
        "    'Fair': 'orange',\n",
        "    'Good': 'green',\n",
        "    'Very Good': 'aqua',\n",
        "    'Exceptional': 'blue'\n",
        "}\n",
        "\n",
        "# Plot FICO classes based on color coding\n",
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "\n",
        "for fico_class, color in fico_colors.items():\n",
        "    # Filter the GeoDataFrame for the current FICO class\n",
        "    subset_gdf = gdf[gdf['fico_score_class'] == fico_class]\n",
        "\n",
        "    # Check if the subset is not empty before plotting\n",
        "    if not subset_gdf.empty:\n",
        "        subset_gdf.plot(\n",
        "            ax=ax,\n",
        "            color=color,\n",
        "            markersize=5,\n",
        "            label=fico_class,\n",
        "            alpha=0.7  # Transparency for overlapping points\n",
        "        )\n",
        "\n",
        "# Customize plot\n",
        "plt.legend(title=\"FICO Class\", loc=\"upper left\")\n",
        "plt.title(\"FICO Class Distribution Across Oromia Region\")\n",
        "plt.xlabel(\"Longitude\")\n",
        "plt.ylabel(\"Latitude\")\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "# Save the figure\n",
        "fig.savefig(\"fico_class_map.png\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dF5VLFXUrl8"
      },
      "outputs": [],
      "source": [
        "!pip install lime\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAAfl6SqVWqr"
      },
      "outputs": [],
      "source": [
        "# Assume merged_data has been processed and contains necessary features\n",
        "# Define features and target\n",
        "features = ['precision_factor', 'inclusion_factor', 'consistency_factor']  # Add other relevant features\n",
        "X = merged_data[features]\n",
        "y = merged_data['fico_class']  # Target variable with classifications: Poor, Fair, Good, etc.\n",
        "\n",
        "# Split the data (if needed) and train a classifier\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Initialize LIME\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    training_data=X_train.values,\n",
        "    feature_names=features,\n",
        "    class_names=['Poor', 'Good', 'Good', 'Very Good', 'Exceptional'],\n",
        "    mode='classification'\n",
        ")\n",
        "\n",
        "# Select a sample to explain\n",
        "i = 0  # Index of the sample in X_test\n",
        "exp = explainer.explain_instance(\n",
        "    data_row=X_test.values[i],\n",
        "    predict_fn=model.predict_proba  # Probability prediction function of the model\n",
        ")\n",
        "\n",
        "# Display the explanation\n",
        "exp.show_in_notebook(show_table=True)\n",
        "# Display and save the explanation plot\n",
        "fig = exp.as_pyplot_figure()\n",
        "fig.savefig(\"lime.png\", format=\"png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIWJF-7jY6sI"
      },
      "outputs": [],
      "source": [
        "# Ensure fico_class column is correctly labeled in merged_data\n",
        "# Define features and target\n",
        "features = ['precision_factor', 'inclusion_factor', 'consistency_factor']  # Add other relevant features\n",
        "X = merged_data[features]\n",
        "y = merged_data['fico_class']  # Target variable with classifications: Poor, Fair, Good, etc.\n",
        "\n",
        "# Check for classes with only one sample\n",
        "class_counts = y.value_counts()\n",
        "classes_with_one_sample = class_counts[class_counts == 1].index.tolist()\n",
        "\n",
        "# If there are classes with only one sample, handle them (e.g., remove or oversample)\n",
        "if classes_with_one_sample:\n",
        "    print(f\"Classes with only one sample: {classes_with_one_sample}\")\n",
        "    X = merged_data[features]\n",
        "    y = merged_data['fico_class']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Initialize and train the classifier\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Initialize LIME explainer\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    training_data=X_train.values,\n",
        "    feature_names=features,\n",
        "    class_names=['Poor', 'Fair', 'Good', 'Very Good', 'Exceptional'],  # The FICO classes\n",
        "    mode='classification'\n",
        ")\n",
        "\n",
        "# Select a sample from the test set to explain (change index if needed)\n",
        "i = 10  # Index of the sample in X_test\n",
        "exp = explainer.explain_instance(\n",
        "    data_row=X_test.values[i],\n",
        "    predict_fn=model.predict_proba  # Probability prediction function of the model\n",
        ")\n",
        "\n",
        "# Display the explanation in the notebook\n",
        "exp.show_in_notebook(show_table=True)\n",
        "\n",
        "# Save and display the explanation plot\n",
        "fig = exp.as_pyplot_figure()\n",
        "fig.savefig(\"lime_explanation_multi_class.png\", format=\"png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dk0vD5BRnQ-S"
      },
      "outputs": [],
      "source": [
        "merged_data = merged_data.join(user_df, on='GRID_CODE', lsuffix='_caller', rsuffix='_other')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tm8wxhvI8u0"
      },
      "outputs": [],
      "source": [
        "print(merged_data.columns)\n",
        "print(user_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axL2Fe7KpFC-"
      },
      "outputs": [],
      "source": [
        "max_users = 50\n",
        "user_counts = np.random.randint(1, max_users + 1, size=len(pico_score_for_each_grid))\n",
        "\n",
        "user_data = []\n",
        "index_list = []\n",
        "for i, grid_code in enumerate(pico_score_for_each_grid['GRID_CODE']):\n",
        "    for j in range(user_counts[i]):\n",
        "        user_data.append({'GRID_CODE': grid_code, 'User': f'user_{len(user_data) + 1}'})\n",
        "        index_list.append(i)\n",
        "user_df = pd.DataFrame(user_data, index=index_list)\n",
        "merged_data = merged_data.merge(user_df, left_on='GRID_CODE_caller', right_on='GRID_CODE', how='left')\n",
        "pico_score_for_each_user = merged_data[['GRID_CODE', 'pico_score',\n",
        "                                        'precision_factor', 'inclusion_factor',\n",
        "                                        'consistency_factor','user_grid']]\n",
        "pico_score_for_each_user.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9Ka_8OusdGa"
      },
      "outputs": [],
      "source": [
        "merged_data = merged_data.join(user_df, lsuffix='_caller', rsuffix='_other')\n",
        "merged_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GvxKdecZwRe"
      },
      "outputs": [],
      "source": [
        "pico_score_for_each_grid.tail(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RbAIZQ-aOoN"
      },
      "outputs": [],
      "source": [
        "adjustment_factor = 0.97\n",
        "merged_data['final_pico_score'] = merged_data['pico_score']*adjustment_factor\n",
        "pico_score_for_each_grid = merged_data[['GRID_CODE', 'final_pico_score',\n",
        "                                        'precision_factor', 'inclusion_factor',\n",
        "                                        'consistency_factor']]\n",
        "pico_score_for_each_grid.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElUm4xgeTsyv"
      },
      "outputs": [],
      "source": [
        "pico_score_for_each_grid.tail(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CGIfH7r2H5T"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "NDVI_Predictor = pickle.load(open('/content/NDVI_Predictor.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sM9fh24q2zUI"
      },
      "outputs": [],
      "source": [
        "NDVI_Predictor.predict()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}